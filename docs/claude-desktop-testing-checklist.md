# Claude Desktop Testing Checklist

## Setup Instructions

### 1. Install Latest Beta
Wait for the beta build to complete, then:
```bash
npm install -g @digitalsamba/mcp-server@beta
```

### 2. Update Claude Desktop Config
Edit your config file (`~/Library/Application Support/Claude/claude_desktop_config.json` on Mac):
```json
{
  "mcpServers": {
    "digital-samba": {
      "command": "npx",
      "args": ["@digitalsamba/mcp-server@beta", "--api-key", "YOUR_API_KEY"]
    }
  }
}
```

### 3. Restart Claude Desktop
Close and reopen Claude Desktop to load the new server.

---

## Natural Language Testing Scenarios

### Room Management Tests

| Test Scenario | Expected Tool/Resource | Notes |
|---------------|------------------------|-------|
| "Create a meeting room" | `create-room` | ‚úÖ Should understand natural request |
| "Set up a private conference for 20 people" | `create-room` | ‚úÖ Should infer privacy and max_participants |
| "Show me all rooms" | `digitalsamba://rooms` | ‚úÖ Should use resource, not tool |
| "Generate a join link for john@email.com" | `generate-token` | ‚úÖ Should understand token generation |
| "Delete the old standup room" | `delete-room` | ‚ö†Ô∏è May need clarification on which room |
| "Update room settings" | `update-room` | ‚ö†Ô∏è May need room ID clarification |

### Analytics & Reporting Tests

| Test Scenario | Expected Tool/Resource | Notes |
|---------------|------------------------|-------|
| "Show me analytics for yesterday" | `get-room-analytics` or analytics resource | ‚úÖ Should understand time context |
| "What's our usage statistics?" | `get-usage-statistics` | ‚úÖ Should map to usage tool |
| "Participant engagement metrics" | `get-participant-statistics` | ‚úÖ Should understand participant focus |
| "Room performance data" | `digitalsamba://analytics/rooms` | ‚úÖ Should use analytics resource |
| "Live session metrics" | `digitalsamba://analytics/live` | ‚úÖ Should understand live context |

### Recording Management Tests

| Test Scenario | Expected Tool/Resource | Notes |
|---------------|------------------------|-------|
| "List all recordings" | `digitalsamba://recordings` | ‚úÖ Should use resource for listing |
| "Show recordings with filters" | `get-recordings` | ‚úÖ Should use tool for filtered results |
| "Download recording ABC123" | `get-recording-download-link` | ‚ö†Ô∏è Needs specific recording ID |
| "Delete old recordings" | `delete-recording` | ‚ö†Ô∏è May need clarification on which ones |
| "Archive recordings from last month" | `archive-recording` | ‚ö†Ô∏è May need batch operation guidance |

### Session Management Tests

| Test Scenario | Expected Tool/Resource | Notes |
|---------------|------------------------|-------|
| "End the current meeting" | `end-session` | ‚ö†Ô∏è Needs session context |
| "Show session summary" | `get-session-summary` | ‚ö†Ô∏è Needs session ID |
| "Delete chat messages" | `delete-session-chats` or `delete-room-chats` | ‚ö†Ô∏è Needs scope clarification |
| "List participants in session" | `digitalsamba://sessions/{id}/participants` | ‚úÖ Should understand participant listing |

### Content Library Tests

| Test Scenario | Expected Tool/Resource | Notes |
|---------------|------------------------|-------|
| "Create a content library" | `create-library` | ‚úÖ Should understand library creation |
| "Upload a presentation file" | `create-library-file` | ‚úÖ Should understand file upload |
| "Show library contents" | `digitalsamba://libraries/{id}` | ‚úÖ Should use resource for viewing |
| "Move files between folders" | `move-library-file` | ‚úÖ Should understand file management |

---

## Advanced Testing Scenarios

### Ambiguous Prompts (Should Ask for Clarification)

| Test Scenario | Expected Behavior | Notes |
|---------------|-------------------|-------|
| "Delete chats" | Ask: session or room scope? | ‚úÖ Should clarify scope |
| "Show analytics" | Ask: which type of analytics? | ‚úÖ Should offer options |
| "Start recording" | Ask: which room? | ‚úÖ Should ask for room context |
| "Export data" | Ask: what type of data? | ‚úÖ Should clarify export type |

### Context-Dependent Tests

| Test Scenario | Expected Behavior | Notes |
|---------------|-------------------|-------|
| "Create room ‚Üí Generate token for that room" | Should remember room ID | ‚úÖ Context retention |
| "Show sessions ‚Üí Get details for first session" | Should use session from previous result | ‚úÖ Reference handling |
| "List recordings ‚Üí Delete the old one" | Should clarify which recording | ‚ö†Ô∏è Ambiguous reference |

### Error Handling Tests

| Test Scenario | Expected Behavior | Notes |
|---------------|-------------------|-------|
| "Delete non-existent room" | Clear error message | ‚úÖ Should handle gracefully |
| Invalid API key | Authentication error | ‚úÖ Should explain auth issue |
| Rate limiting | Retry or clear message | ‚úÖ Should handle API limits |

---

## Quality Checklist

### ‚úÖ Success Criteria

- [ ] **Natural Language Understanding**: Claude understands 90%+ of natural requests
- [ ] **Tool vs Resource Selection**: Correctly chooses between tools (actions) and resources (data)
- [ ] **Parameter Inference**: Can infer obvious parameters from context
- [ ] **Clarification Requests**: Asks good questions for ambiguous requests
- [ ] **Error Handling**: Provides clear, helpful error messages
- [ ] **Context Retention**: Remembers IDs and data from previous operations
- [ ] **Category Understanding**: Groups related operations logically

### ‚ö†Ô∏è Areas to Monitor

- [ ] **Over-clarification**: Too many unnecessary questions
- [ ] **Wrong Tool Selection**: Choosing tools when resources would be better
- [ ] **Parameter Confusion**: Mixing up required vs optional parameters
- [ ] **API Limitations**: How well it handles unsupported operations

### üêõ Issues to Report

- [ ] **Misunderstood Prompts**: Natural language that maps to wrong tools
- [ ] **Missing Context**: When it should remember but doesn't
- [ ] **Confusing Responses**: Unclear error messages or responses
- [ ] **Performance Issues**: Slow responses or timeouts

---

## Testing Notes Template

```
## Testing Session: [Date]
**Beta Version**: [version number]
**API Key Status**: [working/not working]
**Claude Desktop Version**: [version]

### Natural Language Tests
- [‚úÖ/‚ùå] "Create a meeting room" ‚Üí Expected: create-room, Got: ___
- [‚úÖ/‚ùå] "Show analytics" ‚Üí Expected: clarification, Got: ___
- [‚úÖ/‚ùå] "List recordings" ‚Üí Expected: recordings resource, Got: ___

### Issues Found
1. **Issue**: [Description]
   **Expected**: [What should happen]
   **Actual**: [What actually happened]
   **Severity**: [High/Medium/Low]

### Observations
- [General notes about UX, speed, accuracy]
- [Suggestions for improvement]

### Overall Score
**Natural Language Understanding**: [1-10]
**Tool Selection Accuracy**: [1-10]
**Error Handling Quality**: [1-10]
**Overall UX**: [1-10]
```

---

## Next Steps After Testing

1. **Document Issues**: Use the template above to report findings
2. **Prioritize Fixes**: Critical issues vs nice-to-have improvements  
3. **Update Descriptions**: Refine based on actual usage patterns
4. **Production Readiness**: Determine if ready for 1.0 release